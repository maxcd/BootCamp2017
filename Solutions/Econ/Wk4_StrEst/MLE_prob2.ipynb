{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.\n",
    "Estimating an economic model via ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c, k, w, r = np.loadtxt(r'C:\\Users\\Max\\Documents\\BootCamp2017\\Econ\\Wk4_StrEst\\data\\MacroSeries.txt', delimiter=',').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_z_from_3(alpha, mu, k, w):\n",
    "    \n",
    "    z =  np.log(w/((1 - alpha) * k ** alpha))\n",
    "    z_lag1 = np.concatenate([np.array([mu]), z[:-1]])\n",
    "    \n",
    "    return z, z_lag1\n",
    "\n",
    "def norm_loglik(params, *args):\n",
    "    alpha, sigma, rho, mu = params\n",
    "    k, w = args\n",
    "    \n",
    "    z, z_lag = get_z_from_3(alpha, mu, k, w)\n",
    "    z_mean = (rho * z_lag) + (1 - rho) * mu\n",
    "    \n",
    "    loglik = sts.norm(loc=z_mean, scale=sigma).logpdf(z).sum()\n",
    "    \n",
    "    return -1*loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_0 = 0.7\n",
    "sigma_0 = 0.7\n",
    "rho_0 = 0.1\n",
    "mu_0 = 4\n",
    "params_init = (alpha_0, sigma_0, rho_0, mu_0)\n",
    "args_a = (k, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha:\t\t\t 0.914712683312 \n",
      "sigma:\t\t\t 1.00509146545 \n",
      "rho:\t\t\t 0.142783922391 \n",
      "mu :\t\t\t 4.02449563815 \n",
      "LogLikelikhood :\t -93.3694967498\n",
      "\n",
      "Hessian Matrix:\n",
      " [[ 0.08084526 -0.22017763 -0.19433938 -0.06372927]\n",
      " [-0.22017763  1.37852952 -0.01450835 -0.03417128]\n",
      " [-0.19433938 -0.01450835  0.95911674 -0.01293341]\n",
      " [-0.06372927 -0.03417128 -0.01293341  0.99468967]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 93.369496749844799\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-35.47848166,  97.56765849,  -1.3340113 ,  -8.7381494 ])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 30\n",
       "      nit: 3\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.91471268,  1.00509147,  0.14278392,  4.02449564])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_a = opt.minimize(norm_loglik, params_init, args=args_a,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, 1-1e-10), (1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "alpha, sigma, rho, mu = res_a.x\n",
    "ll = -1*res_a.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha:\\t\\t\\t', alpha,\n",
    "      '\\nsigma:\\t\\t\\t', sigma,\n",
    "      '\\nrho:\\t\\t\\t', rho,\n",
    "      '\\nmu :\\t\\t\\t', mu,\n",
    "     '\\nLogLikelikhood :\\t', ll)\n",
    "\n",
    "print('\\nHessian Matrix:\\n', res_a.hess_inv.todense())\n",
    "res_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1692: RuntimeWarning: invalid value encountered in greater\n",
      "  cond0 = self._argcheck(*args) & (scale > 0)\n",
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1693: RuntimeWarning: invalid value encountered in greater\n",
      "  cond1 = self._support_mask(x) & (scale > 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.25,  1.  ,  0.  ,  1.  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to find some better initial guesses here...\n",
    "\n",
    "alphas = np.linspace(1e-10, 1-1e-10, 5)\n",
    "sigmas = np.logspace(1e-10, 100, 5)\n",
    "rhos = np.linspace(1e-10-1, 1-1e-10, 5)\n",
    "mus = np.logspace(1e-10, 30, 5)\n",
    "\n",
    "init_opt = np.array([0, 1, 2, 3])\n",
    "fun_opt = 10000\n",
    "for a in alphas:\n",
    "    for s in sigmas:\n",
    "        for r in rhos:\n",
    "            for m in rhos:\n",
    "                params_iter = np.array([a, s, r, m])\n",
    "                \n",
    "                res_iter = opt.minimize(norm_loglik, params_iter,\n",
    "                                        args=args_a,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, 1-1e-10), (1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "                this_fun = res_iter.fun\n",
    "                if this_fun < fun_opt:\n",
    "                    fun_opt = np.copy(this_fun)\n",
    "                    init_opt = np.copy(params_iter)\n",
    "                    \n",
    "init_opt               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha:\t\t\t 0.457518997955 \n",
      "sigma:\t\t\t 0.091996300808 \n",
      "rho:\t\t\t 0.720488273392 \n",
      "mu :\t\t\t 9.52268275846 \n",
      "LogLikelikhood :\t 96.7069080734\n",
      "\n",
      " Inverse Hessian Matrix:\n",
      " [[  1.36153562e+01  -1.94022855e+00  -1.13673387e+01  -1.84879761e+02]\n",
      " [ -1.94022855e+00   3.11710842e-01   1.74121115e+00   2.62383448e+01]\n",
      " [ -1.13673387e+01   1.74121115e+00   9.92181361e+00   1.53983802e+02]\n",
      " [ -1.84879761e+02   2.62383448e+01   1.53983802e+02   2.51077064e+03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -96.706908073365724\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.00937916,  0.0016442 ,  0.00018758,  0.00066791])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 315\n",
       "      nit: 43\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.457519  ,  0.0919963 ,  0.72048827,  9.52268276])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_opt = opt.minimize(norm_loglik, init_opt, args=args_a,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, 1-1e-10), (1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "alpha_opt, sigma_opt, rho_opt, mu_opt = res_opt.x\n",
    "ll_opt = -1*res_opt.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha:\\t\\t\\t', alpha_opt,\n",
    "      '\\nsigma:\\t\\t\\t', sigma_opt,\n",
    "      '\\nrho:\\t\\t\\t', rho_opt,\n",
    "      '\\nmu :\\t\\t\\t', mu_opt,\n",
    "     '\\nLogLikelikhood :\\t', ll_opt)\n",
    "\n",
    "print('\\n Inverse Hessian Matrix:\\n', res_opt.hess_inv.todense())\n",
    "\n",
    "res_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this result is at least a little more reasonable, however I have had my problems with this problem set...  For this reason consider the following exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A shame that i did all of this before I caught the following though. We also talked about his with Justin a little.\n",
    "    \n",
    "I do not really understand the statement about the distribution of $z_{t}$. How can there be $z_{t-1}$ in the definition of the mean? Is this supposed to be some conditional one-step-ahead kind of distribution? However, this would give me a different mean when setting up my log liklihood and would violate the iid assumptions needed to even being able to set up the likelihood. (I noticed that after getting really weird values for thee loglikelihood, namly positive ones, like above. Hower I found out that this can happen. I was only used to seing negative values for the log logliklihood).\n",
    "Since $z$ is an ar-process its unconditinal mean is just $\\mu$ and its unconditional variance is $\\frac{\\sigma^2}{1-\\rho^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41731988399318171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back out alha from equations 3 and 4\n",
    "alpha_vec = 1/(w/(r*k)+1)\n",
    "alpha = np.mean(alpha_vec)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_z3(alpha, k, w):\n",
    "    \n",
    "    z =  np.log(w/((1 - alpha) * k ** alpha))\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zi = get_z3(alpha, k, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.083681502893953"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a good guess of mu\n",
    "mu_0 = np.mean(zi)\n",
    "mu_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loglik2(params, *args):\n",
    "    sigma, rho, mu = params\n",
    "    k, w, zi, alpha = args\n",
    "    \n",
    "    std_of_zi = sigma/np.sqrt(1 - rho **2)\n",
    "    \n",
    "    loglik = sts.norm.logpdf(zi, loc=mu, scale=std_of_zi).sum()\n",
    "    \n",
    "    return -1*loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some initial values\n",
    "sigma_0 = 12\n",
    "rho_0 = 0.1\n",
    "params_init2 = (sigma_0, rho_0, mu_0)\n",
    "args_a = (k, w, zi, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340.89352991967343"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_loglik2(params_init2, k, w, zi, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha (not estimated):\t 0.417319883993 \n",
      "sigma:\t\t\t 0.137455358099 \n",
      "rho:\t\t\t 1.78364862783e-10 \n",
      "mu :\t\t\t 10.0836817708 \n",
      "LogLikelikhood :\t 56.551572805\n",
      "\n",
      "Inverse Hessian Matrix:\n",
      " [[  1.39971301e-01  -1.56068437e-05  -1.55608049e-01]\n",
      " [ -1.56068437e-05   9.99999999e-01  -4.37566333e-05]\n",
      " [ -1.55608049e-01  -4.37566333e-05   1.73297438e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -56.551572804965993\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.00259774,  0.        ,  0.00144382])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 60\n",
       "      nit: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  1.37455358e-01,   1.78364863e-10,   1.00836818e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I restrit rho to be between 0 and 1 since an a-persistent shock\n",
    "# is usually not what economist bouild into their models\n",
    "\n",
    "res_a2 = opt.minimize(norm_loglik2, params_init2, args=args_a,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, None), \n",
    "                          (0, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "sigma2, rho2, mu2 = res_a2.x\n",
    "ll2 = -1*res_a2.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha (not estimated):\\t', alpha,\n",
    "      '\\nsigma:\\t\\t\\t', sigma2,\n",
    "      '\\nrho:\\t\\t\\t', rho2,\n",
    "      '\\nmu :\\t\\t\\t', mu2,\n",
    "     '\\nLogLikelikhood :\\t', ll2)\n",
    "\n",
    "print('\\nInverse Hessian Matrix:\\n', res_a2.hess_inv.todense())\n",
    "res_a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything but rho seems to be quite stabe regradless of the initial conditions. However, I just thought I coula also rformulate everything in terms of te iid disturbane to z. This is probably the cleanest way of doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_eps(params, *args):\n",
    "    sigma, rho, mu = params\n",
    "    zi = args\n",
    "    \n",
    "    zi_1 = np.concatenate([np.array([mu]), zi[:-1]])\n",
    "    \n",
    "    eps = zi - rho*zi_1 -(1 - rho) * mu\n",
    "    \n",
    "    loglik = sts.norm.logpdf(eps, loc=0, scale=sigma).sum()\n",
    "    \n",
    "    return -1*loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_0 = 12\n",
    "rho_0 = -0.9\n",
    "params_init_eps = [sigma_0, rho_0, mu_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha (not estimated):\t 0.417319883993 \n",
      "sigma:\t\t\t 0.137455359372 \n",
      "rho:\t\t\t -0.900000001937 \n",
      "mu :\t\t\t 10.0836817806 \n",
      "LogLikelikhood :\t 56.551572805\n",
      "\n",
      "Inverse Hessian Matrix:\n",
      " [[  1.40073434e-01  -1.47359866e-04  -1.55425782e-01]\n",
      " [ -1.47359866e-04   9.99999724e-01  -5.27789039e-04]\n",
      " [ -1.55425782e-01  -5.27789039e-04   1.72766374e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -56.551572804955129\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -2.58353339e-03,  -2.34479103e-05,   1.47224455e-03])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 60\n",
       "      nit: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  0.13745536,  -0.9       ,  10.08368178])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_aeps = opt.minimize(norm_eps, params_init_eps, args=(zi),\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "sigma_aeps, rho_aeps, mu_aeps = res_aeps.x\n",
    "ll_aeps = -1*res_aeps.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha (not estimated):\\t', alpha,\n",
    "      '\\nsigma:\\t\\t\\t', sigma_aeps,\n",
    "      '\\nrho:\\t\\t\\t', rho_aeps,\n",
    "      '\\nmu :\\t\\t\\t', mu_aeps,\n",
    "     '\\nLogLikelikhood :\\t', ll_aeps)\n",
    "\n",
    "print('\\nInverse Hessian Matrix:\\n', res_aeps.hess_inv.todense())\n",
    "res_aeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the exact same result as the one above. INcludong the sensitivity of rho on the initial value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_z_from_4(alpha, mu, k, r):\n",
    "    \n",
    "    z = np.log(r / (alpha * k ** (alpha - 1)))\n",
    "    z_lag1 = np.concatenate([np.array([mu]), z[:-1]])\n",
    "    \n",
    "    return z, z_lag1\n",
    "                \n",
    "def norm_loglik_b(params, *args):\n",
    "    alpha, sigma, rho, mu = params\n",
    "    k, r = args\n",
    "    \n",
    "    z, z_lag = get_z_from_4(alpha, mu, k, r)\n",
    "    z_mean = (rho * z_lag) + (1 - rho) * mu\n",
    "    \n",
    "    loglik = sts.norm(loc=z_mean, scale=sigma).logpdf(z).sum()\n",
    "    \n",
    "    return -1*loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.4580235262986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_loglik_b(params_init, k, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha:\t\t\t 0.9999999999 \n",
      "sigma:\t\t\t 1e-10 \n",
      "rho:\t\t\t 0.9999999999 \n",
      "mu :\t\t\t 1e-10 \n",
      "LogLikelikhood :\t 2099.18381261\n",
      "\n",
      "Inverse Hessian Matrix:\n",
      " [[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -2099.1838126068651\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([  1.40779305e+14,   3.50015556e+10,  -2.08769961e+00,\n",
       "         3.50999721e+11])\n",
       "  message: b'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
       "     nfev: 365\n",
       "      nit: 12\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([  1.00000000e+00,   1.00000000e-10,   1.00000000e+00,\n",
       "         1.00000000e-10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_b = (k, r)\n",
    "other_inits = np.array([1,  0.1,  0.9,  7])\n",
    "\n",
    "res_opt_b = opt.minimize(norm_loglik_b, init_opt, args=args_b,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, 1-1e-10), (1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "alpha_opt_b, sigma_opt_b, rho_opt_b, mu_opt_b = res_opt_b.x\n",
    "ll_opt_b = -1*res_opt_b.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha:\\t\\t\\t', alpha_opt_b,\n",
    "      '\\nsigma:\\t\\t\\t', sigma_opt_b,\n",
    "      '\\nrho:\\t\\t\\t', rho_opt_b,\n",
    "      '\\nmu :\\t\\t\\t', mu_opt_b,\n",
    "     '\\nLogLikelikhood :\\t', ll_opt_b)\n",
    "\n",
    "print('\\nInverse Hessian Matrix:\\n', res_opt_b.hess_inv.todense())\n",
    "\n",
    "res_opt_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look good. This approach is just not valid in MLE, correct? I can't just construct a log likelihood function out of serially correlated terms. The independence assumptions shich allows me to multiply the pdf's of the single observations is clearly not given in his case.\n",
    "\n",
    "We can get $\\alpha$ and have the good initial guess for $\\mu$ in the same way we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.082870874830103"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_z4(alpha, r, w):\n",
    "    \n",
    "    z = np.log(r / (alpha * k ** (alpha - 1)))\n",
    "    \n",
    "    return z\n",
    "\n",
    "zi = get_z4(alpha, r, w)\n",
    "\n",
    "# This looks good but a little different than earlier.\n",
    "mu4 = np.mean(zi)\n",
    "mu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loglik4(params, *args):\n",
    "    sigma, rho, mu = params\n",
    "    zi, alpha = args\n",
    "    \n",
    "    std_of_zi = sigma/np.sqrt(1 - rho **2)\n",
    "    \n",
    "    loglik = sts.norm.logpdf(zi, loc=mu, scale=std_of_zi).sum()\n",
    "    \n",
    "    return -1*loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha (not estimated):\t 0.417319883993 \n",
      "sigma:\t\t\t 0.119379231299 \n",
      "rho:\t\t\t 0.0725624871089 \n",
      "mu :\t\t\t 10.0828711265 \n",
      "LogLikelikhood :\t 70.3871858225\n",
      "\n",
      " Inverse Hessian Matrix:\n",
      " [[  1.22466360e-04  -4.86741312e-03   2.99544814e-03]\n",
      " [ -4.86741312e-03   5.59595191e-01  -2.79602493e-04]\n",
      " [  2.99544814e-03  -2.79602493e-04   9.99942238e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -70.387185822535841\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([  1.56319402e-05,  -1.42108547e-06,   1.79056769e-03])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 52\n",
       "      nit: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  0.11937923,   0.07256249,  10.08287113])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_0 = 0.7\n",
    "rho_0 = 0.4\n",
    "params_initb2 = (sigma_0, rho_0, mu4)\n",
    "args_b2 = (zi, alpha)\n",
    "\n",
    "res_b2 = opt.minimize(norm_loglik4, params_initb2, args=args_b2,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, None), \n",
    "                          (0, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "sigmab2, rhob2, mub2 = res_b2.x\n",
    "llb2 = -1*res_b2.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha (not estimated):\\t', alpha,\n",
    "      '\\nsigma:\\t\\t\\t', sigmab2,\n",
    "      '\\nrho:\\t\\t\\t', rhob2,\n",
    "      '\\nmu :\\t\\t\\t', mub2,\n",
    "     '\\nLogLikelikhood :\\t', llb2)\n",
    "\n",
    "print('\\n Inverse Hessian Matrix:\\n', res_b2.hess_inv.todense())\n",
    "res_b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reassuring beccause the results look very much like the results in part a). \n",
    "\n",
    "And once more just reformulating everything interms of epsilon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results \n",
      "\n",
      "alpha (not estimated):\t 0.417319883993 \n",
      "sigma:\t\t\t 0.119694768829 \n",
      "rho:\t\t\t -0.124000025949 \n",
      "mu :\t\t\t 10.0828708472 \n",
      "LogLikelikhood :\t 70.3871858228\n",
      "\n",
      "Inverse Hessian Matrix:\n",
      " [[  7.12299286e-05   4.42192780e-07   1.12091145e-06]\n",
      " [  4.42192780e-07   1.00000000e+00  -1.10490966e-06]\n",
      " [  1.12091145e-06  -1.10490966e-06   1.40543044e-04]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: -70.387185822754219\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.00010516,  0.        , -0.00015774])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 108\n",
       "      nit: 10\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  0.11969477,  -0.12400003,  10.08287085])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_0 = 15\n",
    "rho_0 = -0.124\n",
    "params_eps2 = [sigma_0, rho_0, 16]\n",
    "\n",
    "res_beps = opt.minimize(norm_eps, params_eps2, args=(zi),\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=((1e-10, None), \n",
    "                          (1e-10-1, 1-1e-10), (1e-10, 30))\n",
    "                    )\n",
    "\n",
    "sigma_beps, rho_beps, mu_beps = res_beps.x\n",
    "ll_beps = -1*res_beps.fun\n",
    "\n",
    "print('Estimation results',\n",
    "      '\\n\\nalpha (not estimated):\\t', alpha,\n",
    "      '\\nsigma:\\t\\t\\t', sigma_beps,\n",
    "      '\\nrho:\\t\\t\\t', rho_beps,\n",
    "      '\\nmu :\\t\\t\\t', mu_beps,\n",
    "     '\\nLogLikelikhood :\\t', ll_beps)\n",
    "\n",
    "print('\\nInverse Hessian Matrix:\\n', res_beps.hess_inv.todense())\n",
    "res_beps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result here, even for crazy guesses sigma and mu come close to the values of 0.12 and 10. Only rho is not  estimated precicely at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate z_star for r=1 and k=7500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_star = np.log(1/(alpha * 7500000 **(alpha -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_cdf(z_star, sigma, rho, mu):                             \n",
    "    \n",
    "    std_of_zi = sigma/np.sqrt(1 - rho **2)\n",
    "    \n",
    "    cdf_vals = sts.norm.cdf(z_star, loc=mu, scale=std_of_zi)\n",
    "    \n",
    "    return cdf_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44981042052737463"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - z_cdf(z_star, sigmab2, rhob2, mub2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that r is higher than one in the next period is approximately 0.45."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
